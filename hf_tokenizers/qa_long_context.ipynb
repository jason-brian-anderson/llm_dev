{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1490f0d-b8ec-4ad0-9446-16f4f80849db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Which deep learning libraries back ðŸ¤— Transformers?\"\n",
    "\n",
    "context = \"\"\"\n",
    "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900bb80-b9ca-447d-9e09-c4a7f8704668",
   "metadata": {},
   "source": [
    "## Get start/end output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90217c5-1853-4da6-a34e-56a6d5f9b2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f9012c-abad-4336-9988-6373f198057f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 67]) torch.Size([1, 67])\n"
     ]
    }
   ],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "print(start_logits.shape, end_logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a5fb6-1ba5-4959-a683-6ccbc4281128",
   "metadata": {},
   "source": [
    "## Mask output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735c7ddf-cf4b-467d-b4bc-9b46db0ff339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sequence_ids = inputs.sequence_ids()\n",
    "# Mask everything apart from the tokens of the context\n",
    "mask = [i != 1 for i in sequence_ids]\n",
    "# Unmask the [CLS] token\n",
    "mask[0] = False\n",
    "#mask\n",
    "\n",
    "mask = torch.tensor(mask)[None]  #End None gives it a column orientation i beleive.\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb37b31b-4535-4fd5-a311-aaf027800a44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368, -5.9199,\n",
       "        -5.4193, -5.4193], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e539c8-f049-4717-a595-224ffffb0006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mask them!!\n",
    "\n",
    "start_logits[mask] = -10000\n",
    "end_logits[mask] = -10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85471877-7b71-414a-bf0b-31a622c11edd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#start_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cfb22a-153d-4e79-a09a-7a19e662a465",
   "metadata": {},
   "source": [
    "## Softmaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a669a088-d116-4dff-a1f9-a59514bf6912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
    "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656083f-f22f-4c3d-9ae1-4bc9781ff46b",
   "metadata": {},
   "source": [
    "## Scores Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574422f2-95e7-4c1d-a719-b57daabeb3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colum vector matrix multiplication of start/end probabilities\n",
    "scores = start_probabilities[:, None] * end_probabilities[None, :]\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316a575-71f9-4610-949b-109daf7974b9",
   "metadata": {},
   "source": [
    "## Upper triangulate as lower half is duplicate of top half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af7f6893-97d9-49d9-a024-8376f40d519a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix is duplicated over i=j and is symmetric.  get rid of the duplicate half\n",
    "scores = torch.triu(scores)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03f6e8-ae50-45b7-ac81-4dd8bb8ff52f",
   "metadata": {},
   "source": [
    "## Topk scores - note that scores will be flattened here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82d933fd-c9b9-4de7-9b43-e240f212b03d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.4340e-13, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.view(-1)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1833ce9-7ec2-4fe2-a5d2-9ab6520cc646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 5 largest values and their indices in the `scores` tensor\n",
    "top_k_values, top_k_indices = torch.topk(scores.view(-1), k=5)\n",
    "# 5 element vals tensor\n",
    "# 5 element tuple tensor\n",
    "top_k_values.shape, top_k_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a472dedb-a89e-46c7-940c-8cc0a75f7c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1576, 1577, 1107, 1570, 1710]),\n",
       " tensor([9.8026e-01, 8.2478e-03, 6.8415e-03, 1.3677e-03, 3.8109e-04],\n",
       "        grad_fn=<TopkBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_indices, top_k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28a39dbb-3af6-4629-88af-c213a318afe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([23, 23, 16, 23, 25]), tensor([35, 36, 35, 29, 35]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract the row and column indices of the top 5 largest values\n",
    "row_indices = top_k_indices // scores.shape[1]\n",
    "column_indices = top_k_indices % scores.shape[1]\n",
    "\n",
    "row_indices, column_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5877fa-e6d2-4b3a-b9b9-9bc008218d18",
   "metadata": {},
   "source": [
    "### How does topk work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e810269-a921-439e-8f33-7efcc385ce09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[93],\n",
       "        [ 6],\n",
       "        [ 4]]),\n",
       "indices=tensor([[2],\n",
       "        [2],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,93,],[4,5,6,],[3,4,4,]]\n",
    "x = torch.tensor(x)\n",
    "print(x.shape)\n",
    "torch.topk(x,k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158794e-126f-4809-87f6-3589e059664f",
   "metadata": {},
   "source": [
    "## Top K predicted answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f501fb8-5d23-43d9-879c-feb4337a0a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: 0.9802601933479309 (start_index: 23, end_index: 35), answer: Jax, PyTorch, and TensorFlow\n",
      "index 1: 0.008247788064181805 (start_index: 23, end_index: 36), answer: Jax, PyTorch, and TensorFlow â€”\n",
      "index 2: 0.00684146536514163 (start_index: 16, end_index: 35), answer: three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow\n",
      "index 3: 0.0013676981907337904 (start_index: 23, end_index: 29), answer: Jax, PyTorch\n",
      "index 4: 0.0003810854977928102 (start_index: 25, end_index: 35), answer: PyTorch, and TensorFlow\n"
     ]
    }
   ],
   "source": [
    "def map_index_to_offsets(start_index, end_index):\n",
    "    inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
    "    offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "    start_char, _ = offsets[start_index]\n",
    "    _, end_char = offsets[end_index]\n",
    "    answer = context[start_char:end_char]\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "# Flatten the scores tensor and find the top 5 largest values and their indices\n",
    "top_k_values, top_k_indices = torch.topk(scores.view(-1), k=5)\n",
    "\n",
    "# Calculate the row and column indices of the top 5 largest values\n",
    "row_indices = top_k_indices // scores.shape[1]\n",
    "column_indices = top_k_indices % scores.shape[1]\n",
    "\n",
    "# Print the top 5 largest values and their indices\n",
    "for i in range(5):\n",
    "    start_index = row_indices[i].item()\n",
    "    end_index = column_indices[i].item()\n",
    "    answer = map_index_to_offsets(start_index, end_index)\n",
    "    #context[start_char:end_char]\n",
    "    \n",
    "    value = top_k_values[i].item()\n",
    "    print(f\"index {i }: {value} (start_index: {start_index}, end_index: {end_index}), answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed54f82-9471-438a-9a1c-9baf735e474e",
   "metadata": {},
   "source": [
    "## Check topk method against argmax method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bef8706d-3e90-48fc-a435-692e3adbfc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = scores.argmax().item()\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0bcf80c-521d-4bd7-817b-6a761f1bbd90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 35)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index // scores.shape[1],max_index % scores.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23ad7c56-2150-4519-919c-64189d1a6ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9803, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_index = max_index // scores.shape[1]\n",
    "end_index = max_index % scores.shape[1]\n",
    "print(scores[start_index, end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b94e3e1-d17e-4228-9c99-a33ce393b897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jax, PyTorch, and TensorFlow'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "start_char, _ = offsets[start_index]\n",
    "_, end_char = offsets[end_index]\n",
    "answer = context[start_char:end_char]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71770603-10df-4c75-b6a8-ada09ec04533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 106)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets[start_index]\n",
    "offsets[end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "153760e0-44b6-4729-870b-d1a88635a86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 106)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_char, end_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a7e61-8a74-40ca-a0c7-3a04752a0aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
